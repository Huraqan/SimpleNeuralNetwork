{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "Data is loaded as three lists of tuples for `training_data`, `validation_data` and `test_data`. The tuples contain the input and the expected output as column vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_handler import load_data_wrapper, show_as_image\n",
    "\n",
    "training_data, validation_data, test_data = load_data_wrapper(noise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an instance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.SimpleNeuralNetwork import SimpleNeuralNetwork\n",
    "\n",
    "NAME = \"neural_network\"\n",
    "EPOCHS = 3\n",
    "SIZES = [28 * 28, 49, 16, 10]\n",
    "\n",
    "net = SimpleNeuralNetwork(sizes=SIZES)\n",
    "# net = SimpleNeuralNetwork.load_from_file(fp= NAME + \".pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network\n",
    "The model's train_network function can be called with the list of training tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network of size: [784, 49, 16, 10]\n",
      "Number of finished epochs on this instance: 0\n",
      "\n",
      "=== EPOCH: 1 / 3 ============================================================================\n",
      "\n",
      "Done! Average score during training: \u001b[92m||||||||||||||||||||||||||||||||||\u001b[0m\u001b[91m||||||||||||||||\u001b[0m  0.695\n",
      "\n",
      "File saved as neural_network.pickle \n",
      "\n",
      "\n",
      "=== EPOCH: 2 / 3 ============================================================================\n",
      "\n",
      "Done! Average score during training: \u001b[92m|||||||||||||||||||||||||||||||||||||||||||\u001b[0m\u001b[91m|||||||\u001b[0m  0.864\n",
      "\n",
      "File saved as neural_network.pickle \n",
      "\n",
      "\n",
      "=== EPOCH: 3 / 3 ============================================================================\n",
      "\n",
      "Done! Average score during training: \u001b[92m||||||||||||||||||||||||||||||||||||||||||||\u001b[0m\u001b[91m||||||\u001b[0m  0.898\n",
      "\n",
      "File saved as neural_network.pickle \n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.train_network(training_data, batch_size=100, epochs=EPOCHS, filepath= NAME + \".pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 samples, final score: \u001b[92m|||||||||||||||||||||||||||||||||||||||||||||\u001b[0m\u001b[91m|||||\u001b[0m  0.914                            \n"
     ]
    }
   ],
   "source": [
    "net.validate(test_data, csv_path= NAME + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OUTPUT  SIMPLE  SOFTMAX\n",
      "0   0.001   0.001    0.088\n",
      "1   0.001   0.001    0.088\n",
      "2   0.757   0.810    0.188\n",
      "3   0.132   0.141    0.101\n",
      "4   0.000   0.000    0.088\n",
      "5   0.001   0.001    0.088\n",
      "6   0.000   0.000    0.088\n",
      "7   0.001   0.001    0.088\n",
      "8   0.013   0.014    0.089\n",
      "9   0.029   0.031    0.091 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp, exp_out = test_data[4260]\n",
    "show_as_image(inp)\n",
    "\n",
    "output = net.predict(inp, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
